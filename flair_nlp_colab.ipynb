{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"flair_nlp_colab.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["df7YLR6ZBNww"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ISi146ydAEVT","colab_type":"text"},"source":["##**Connect to drive**:"]},{"cell_type":"code","metadata":{"id":"F6IdLMnmKTav","colab_type":"code","outputId":"e0f4a1d7-0dc0-4fd0-9081-87c9c16316a6","executionInfo":{"status":"ok","timestamp":1560919454627,"user_tz":-120,"elapsed":29353,"user":{"displayName":"Quantum Orange","photoUrl":"https://lh5.googleusercontent.com/--VkGsCpIv4k/AAAAAAAAAAI/AAAAAAAAAkA/r5sV6ZbDvIM/s64/photo.jpg","userId":"11682791397544069015"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7RQVl2JdAV7C","colab_type":"text"},"source":["##**Change repository:**"]},{"cell_type":"code","metadata":{"id":"xBUmm_D_LGXw","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/gdrive/My Drive/flair') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-5JNA4NU7e9","colab_type":"code","outputId":"51638fbb-f3f5-4cfd-ec03-d48791dfacd5","executionInfo":{"status":"ok","timestamp":1560919494253,"user_tz":-120,"elapsed":19535,"user":{"displayName":"Quantum Orange","photoUrl":"https://lh5.googleusercontent.com/--VkGsCpIv4k/AAAAAAAAAAI/AAAAAAAAAkA/r5sV6ZbDvIM/s64/photo.jpg","userId":"11682791397544069015"}},"colab":{"base_uri":"https://localhost:8080/","height":1312}},"source":["pip install flair"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting flair\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/3a/2e777f65a71c1eaa259df44c44e39d7071ba8c7780a1564316a38bf86449/flair-0.4.2-py3-none-any.whl (136kB)\n","\u001b[K     |████████████████████████████████| 143kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n","Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n","Collecting segtok>=1.5.7 (from flair)\n","  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n","Collecting pytorch-pretrained-bert>=0.6.1 (from flair)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 48.8MB/s \n","\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n","Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n","Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n","Collecting mpld3==0.3 (from flair)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n","\u001b[K     |████████████████████████████████| 798kB 54.5MB/s \n","\u001b[?25hCollecting sqlitedict>=1.6.0 (from flair)\n","  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n","Collecting deprecated>=1.2.4 (from flair)\n","  Downloading https://files.pythonhosted.org/packages/9f/7a/003fa432f1e45625626549726c2fbb7a29baa764e9d1fdb2323a5d779f8a/Deprecated-1.2.5-py2.py3-none-any.whl\n","Collecting bpemb>=0.2.9 (from flair)\n","  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n","Collecting regex (from flair)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n","\u001b[K     |████████████████████████████████| 655kB 47.9MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->flair) (1.16.4)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.12.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.0.1)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.167)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n","Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n","Collecting sentencepiece (from bpemb>=0.2.9->flair)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/95/7f357995d5eb1131aa2092096dca14a6fc1b1d2860bd99c22a612e1d1019/sentencepiece-0.1.82-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 48.3MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.13.2)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.167 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.167)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.167->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n","Building wheels for collected packages: segtok, mpld3, sqlitedict, regex\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n","Successfully built segtok mpld3 sqlitedict regex\n","Installing collected packages: regex, segtok, pytorch-pretrained-bert, mpld3, sqlitedict, deprecated, sentencepiece, bpemb, flair\n","Successfully installed bpemb-0.3.0 deprecated-1.2.5 flair-0.4.2 mpld3-0.3 pytorch-pretrained-bert-0.6.2 regex-2019.6.8 segtok-1.5.7 sentencepiece-0.1.82 sqlitedict-1.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K3TuNhMoAfY8","colab_type":"text"},"source":["##**Import train and test data from corpus:**"]},{"cell_type":"code","metadata":{"id":"o7MKh36mLdNG","colab_type":"code","outputId":"6f07ba21-4d72-446a-ab8e-a49bc6c33f3a","executionInfo":{"status":"ok","timestamp":1560919508840,"user_tz":-120,"elapsed":6040,"user":{"displayName":"Quantum Orange","photoUrl":"https://lh5.googleusercontent.com/--VkGsCpIv4k/AAAAAAAAAAI/AAAAAAAAAkA/r5sV6ZbDvIM/s64/photo.jpg","userId":"11682791397544069015"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["# imports \n","from flair.data import Corpus\n","from flair.datasets import ColumnCorpus\n","from typing import List\n","\n","# columns of \"gold standard\" ner annotations and text\n","columns = {0: 'text', 1: 'ner'}\n","\n","# folder where training and test data are\n","data_folder = \"./\"\n","\n","# 2. what tag do we want to predict?\n","tag_type = 'ner'\n","\n","downsample = 1 # 1.0 is full data, try a much smaller number like 0.01 to test run the code\n","\n","# 1. get the corpus\n","corpus: Corpus = ColumnCorpus(data_folder, columns, train_file='train.txt', test_file='test.txt', dev_file=None).downsample(downsample)\n","\n","print(corpus)\n","\n","# 3. make the tag dictionary from the corpus\n","tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n","print(tag_dictionary.idx2item)\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["2019-06-19 04:45:03,630 Reading data from .\n","2019-06-19 04:45:03,631 Train: train.txt\n","2019-06-19 04:45:03,632 Dev: None\n","2019-06-19 04:45:03,641 Test: test.txt\n","Corpus: 6440 train + 716 dev + 1956 test sentences\n","[b'<unk>', b'O', b'-', b'B-Companies', b'L-Companies', b'B-College', b'I-College', b'L-College', b'U-Companies', b'I-Companies', b'B-Degree', b'I-Degree', b'L-Degree', b'U-Degree', b'<START>', b'<STOP>']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C-wqWNWTAu4u","colab_type":"text"},"source":["#**Train model with StackedEmbeddings**"]},{"cell_type":"markdown","metadata":{"id":"l9cW8BLDv2Yp","colab_type":"text"},"source":["##**Training with current best configuration for NER:**"]},{"cell_type":"code","metadata":{"id":"hP2450p1v1c5","colab_type":"code","outputId":"df7a30ed-b962-4737-e36e-935c590bb2f9","executionInfo":{"status":"ok","timestamp":1560919556048,"user_tz":-120,"elapsed":34187,"user":{"displayName":"Quantum Orange","photoUrl":"https://lh5.googleusercontent.com/--VkGsCpIv4k/AAAAAAAAAAI/AAAAAAAAAkA/r5sV6ZbDvIM/s64/photo.jpg","userId":"11682791397544069015"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["# 4. initialize embeddings. Experiment with different embedding types to see what gets the best results\n","from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings, PooledFlairEmbeddings\n","embedding_types: List[TokenEmbeddings] = [\n","    \n","    WordEmbeddings('glove'),\n","    \n","    #contextual string embeddings, forward\n","    PooledFlairEmbeddings('news-forward', pooling='min'),\n","\n","    #contextual string embeddings, backward\n","    PooledFlairEmbeddings('news-backward', pooling='min'),\n","]\n","\n","embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n","\n","# 5. initialize sequence tagger\n","from flair.models import SequenceTagger\n","\n","tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n","                                        embeddings=embeddings,\n","                                        tag_dictionary=tag_dictionary,\n","                                        tag_type=tag_type,\n","                                        use_crf=True)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["2019-06-19 04:45:20,851 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpb3s987wg\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 160000128/160000128 [00:08<00:00, 19076655.02B/s]"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:29,823 copying /tmp/tmpb3s987wg to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:30,024 removing temp file /tmp/tmpb3s987wg\n","2019-06-19 04:45:30,520 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmptxesyxei\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 21494764/21494764 [00:01<00:00, 11742578.81B/s]"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:32,879 copying /tmp/tmptxesyxei to cache at /root/.flair/embeddings/glove.gensim\n","2019-06-19 04:45:32,902 removing temp file /tmp/tmptxesyxei\n"],"name":"stdout"},{"output_type":"stream","text":["\n","/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:34,522 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpfml4vjat\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 73034624/73034624 [00:04<00:00, 17070448.24B/s]"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:39,350 copying /tmp/tmpfml4vjat to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:39,435 removing temp file /tmp/tmpfml4vjat\n","2019-06-19 04:45:47,482 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpu5kdp8ez\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 73034575/73034575 [00:04<00:00, 16638564.14B/s]"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:52,437 copying /tmp/tmpu5kdp8ez to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["2019-06-19 04:45:52,515 removing temp file /tmp/tmpu5kdp8ez\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V6wnmFvZv1F_","colab_type":"code","outputId":"3bda2690-7e69-4313-f612-63791819530b","executionInfo":{"status":"ok","timestamp":1560263074207,"user_tz":-120,"elapsed":2326494,"user":{"displayName":"Quantum Orange","photoUrl":"https://lh5.googleusercontent.com/--VkGsCpIv4k/AAAAAAAAAAI/AAAAAAAAAkA/r5sV6ZbDvIM/s64/photo.jpg","userId":"11682791397544069015"}},"colab":{"base_uri":"https://localhost:8080/","height":15249}},"source":["# 6. initialize trainer\n","from flair.trainers import ModelTrainer\n","\n","trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n","\n","# 7. start training\n","trainer.train('resources_best_config/taggers/resume-ner',\n","              #learning_rate=0.1,\n","              #mini_batch_size=32,\n","              max_epochs=150)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2019-06-19 04:46:02,569 ----------------------------------------------------------------------------------------------------\n","2019-06-19 04:46:02,574 Evaluation method: MICRO_F1_SCORE\n","2019-06-19 04:46:03,757 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 04:46:07,572 epoch 1 - iter 0/202 - loss 92.47586060\n","2019-06-19 04:46:26,688 epoch 1 - iter 20/202 - loss 10.18699500\n","2019-06-19 04:46:45,654 epoch 1 - iter 40/202 - loss 6.51050393\n","2019-06-19 04:47:02,467 epoch 1 - iter 60/202 - loss 5.43989021\n","2019-06-19 04:47:23,452 epoch 1 - iter 80/202 - loss 4.61708057\n","2019-06-19 04:47:43,798 epoch 1 - iter 100/202 - loss 4.14494569\n","2019-06-19 04:48:00,713 epoch 1 - iter 120/202 - loss 3.80493010\n","2019-06-19 04:48:21,010 epoch 1 - iter 140/202 - loss 3.54395373\n","2019-06-19 04:48:42,543 epoch 1 - iter 160/202 - loss 3.33023852\n","2019-06-19 04:49:05,868 epoch 1 - iter 180/202 - loss 3.21525037\n","2019-06-19 04:49:25,262 epoch 1 - iter 200/202 - loss 3.07324366\n","2019-06-19 04:49:26,215 ----------------------------------------------------------------------------------------------------\n","2019-06-19 04:49:26,217 EPOCH 1 done: loss 3.0606 - lr 0.1000 - bad epochs 0\n","2019-06-19 04:49:44,204 DEV : loss 1.3080261945724487 - score 0.5198\n","2019-06-19 04:50:51,484 TEST : loss 1.6121070384979248 - score 0.5075\n","2019-06-19 04:51:07,783 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 04:51:09,571 epoch 2 - iter 0/202 - loss 1.37501276\n","2019-06-19 04:51:32,180 epoch 2 - iter 20/202 - loss 1.79960109\n","2019-06-19 04:51:51,609 epoch 2 - iter 40/202 - loss 1.81137472\n","2019-06-19 04:52:10,010 epoch 2 - iter 60/202 - loss 1.67193793\n","2019-06-19 04:52:35,032 epoch 2 - iter 80/202 - loss 1.62259396\n","2019-06-19 04:52:56,582 epoch 2 - iter 100/202 - loss 1.61578054\n","2019-06-19 04:53:17,691 epoch 2 - iter 120/202 - loss 1.60004063\n","2019-06-19 04:53:36,206 epoch 2 - iter 140/202 - loss 1.62024855\n","2019-06-19 04:53:55,341 epoch 2 - iter 160/202 - loss 1.63393106\n","2019-06-19 04:54:12,772 epoch 2 - iter 180/202 - loss 1.62050552\n","2019-06-19 04:54:33,935 epoch 2 - iter 200/202 - loss 1.63808317\n","2019-06-19 04:54:35,328 ----------------------------------------------------------------------------------------------------\n","2019-06-19 04:54:35,330 EPOCH 2 done: loss 1.6372 - lr 0.1000 - bad epochs 0\n","2019-06-19 04:54:53,742 DEV : loss 1.1041111946105957 - score 0.281\n","2019-06-19 04:56:01,505 TEST : loss 1.503955602645874 - score 0.2198\n","2019-06-19 04:56:01,512 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 04:56:03,841 epoch 3 - iter 0/202 - loss 1.20458710\n","2019-06-19 04:56:21,819 epoch 3 - iter 20/202 - loss 1.41700459\n","2019-06-19 04:56:40,756 epoch 3 - iter 40/202 - loss 1.43790174\n","2019-06-19 04:57:02,761 epoch 3 - iter 60/202 - loss 1.50137060\n","2019-06-19 04:57:22,393 epoch 3 - iter 80/202 - loss 1.53644259\n","2019-06-19 04:57:41,474 epoch 3 - iter 100/202 - loss 1.52850407\n","2019-06-19 04:58:02,745 epoch 3 - iter 120/202 - loss 1.51710502\n","2019-06-19 04:58:22,198 epoch 3 - iter 140/202 - loss 1.50046870\n","2019-06-19 04:58:43,394 epoch 3 - iter 160/202 - loss 1.50484719\n","2019-06-19 04:59:02,776 epoch 3 - iter 180/202 - loss 1.49496753\n","2019-06-19 04:59:27,933 epoch 3 - iter 200/202 - loss 1.49365716\n","2019-06-19 04:59:29,263 ----------------------------------------------------------------------------------------------------\n","2019-06-19 04:59:29,264 EPOCH 3 done: loss 1.4901 - lr 0.1000 - bad epochs 1\n","2019-06-19 04:59:49,846 DEV : loss 0.9833235740661621 - score 0.3413\n","2019-06-19 05:00:56,455 TEST : loss 1.3022648096084595 - score 0.2771\n","2019-06-19 05:00:56,462 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:00:58,067 epoch 4 - iter 0/202 - loss 1.29658508\n","2019-06-19 05:01:16,837 epoch 4 - iter 20/202 - loss 1.63666540\n","2019-06-19 05:01:43,493 epoch 4 - iter 40/202 - loss 1.50564981\n","2019-06-19 05:02:05,231 epoch 4 - iter 60/202 - loss 1.53000640\n","2019-06-19 05:02:24,857 epoch 4 - iter 80/202 - loss 1.46327614\n","2019-06-19 05:02:44,932 epoch 4 - iter 100/202 - loss 1.48511375\n","2019-06-19 05:03:03,841 epoch 4 - iter 120/202 - loss 1.44338088\n","2019-06-19 05:03:24,628 epoch 4 - iter 140/202 - loss 1.45058032\n","2019-06-19 05:03:43,521 epoch 4 - iter 160/202 - loss 1.43986603\n","2019-06-19 05:04:00,889 epoch 4 - iter 180/202 - loss 1.42215643\n","2019-06-19 05:04:23,405 epoch 4 - iter 200/202 - loss 1.41578582\n","2019-06-19 05:04:24,604 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:04:24,606 EPOCH 4 done: loss 1.4116 - lr 0.1000 - bad epochs 2\n","2019-06-19 05:04:43,223 DEV : loss 0.9785377979278564 - score 0.5014\n","2019-06-19 05:05:49,873 TEST : loss 1.2406377792358398 - score 0.4937\n","2019-06-19 05:05:49,882 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:05:53,836 epoch 5 - iter 0/202 - loss 0.99822849\n","2019-06-19 05:06:13,716 epoch 5 - iter 20/202 - loss 1.31756217\n","2019-06-19 05:06:41,768 epoch 5 - iter 40/202 - loss 1.43819850\n","2019-06-19 05:07:00,757 epoch 5 - iter 60/202 - loss 1.33779065\n","2019-06-19 05:07:20,590 epoch 5 - iter 80/202 - loss 1.35566062\n","2019-06-19 05:07:37,803 epoch 5 - iter 100/202 - loss 1.36663505\n","2019-06-19 05:07:57,354 epoch 5 - iter 120/202 - loss 1.35191496\n","2019-06-19 05:08:14,214 epoch 5 - iter 140/202 - loss 1.35596511\n","2019-06-19 05:08:32,747 epoch 5 - iter 160/202 - loss 1.35097469\n","2019-06-19 05:08:52,575 epoch 5 - iter 180/202 - loss 1.35575407\n","2019-06-19 05:09:16,520 epoch 5 - iter 200/202 - loss 1.35092388\n","2019-06-19 05:09:17,874 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:09:17,876 EPOCH 5 done: loss 1.3545 - lr 0.1000 - bad epochs 3\n","2019-06-19 05:09:38,549 DEV : loss 0.935264527797699 - score 0.1753\n","2019-06-19 05:10:45,333 TEST : loss 1.242235541343689 - score 0.095\n","Epoch     4: reducing learning rate of group 0 to 5.0000e-02.\n","2019-06-19 05:10:45,342 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:10:47,062 epoch 6 - iter 0/202 - loss 0.92692447\n","2019-06-19 05:11:10,833 epoch 6 - iter 20/202 - loss 1.14881490\n","2019-06-19 05:11:35,129 epoch 6 - iter 40/202 - loss 1.21105397\n","2019-06-19 05:11:55,127 epoch 6 - iter 60/202 - loss 1.31161299\n","2019-06-19 05:12:14,486 epoch 6 - iter 80/202 - loss 1.26296620\n","2019-06-19 05:12:35,203 epoch 6 - iter 100/202 - loss 1.25958957\n","2019-06-19 05:12:55,469 epoch 6 - iter 120/202 - loss 1.25454010\n","2019-06-19 05:13:21,916 epoch 6 - iter 140/202 - loss 1.21253973\n","2019-06-19 05:13:39,819 epoch 6 - iter 160/202 - loss 1.22524458\n","2019-06-19 05:13:57,703 epoch 6 - iter 180/202 - loss 1.23583184\n","2019-06-19 05:14:15,319 epoch 6 - iter 200/202 - loss 1.21090121\n","2019-06-19 05:14:16,747 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:14:16,749 EPOCH 6 done: loss 1.2107 - lr 0.0500 - bad epochs 0\n","2019-06-19 05:14:35,525 DEV : loss 0.8751698732376099 - score 0.5014\n","2019-06-19 05:15:43,802 TEST : loss 1.1383253335952759 - score 0.5118\n","2019-06-19 05:15:43,811 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:15:45,642 epoch 7 - iter 0/202 - loss 0.60712028\n","2019-06-19 05:16:04,602 epoch 7 - iter 20/202 - loss 1.08002055\n","2019-06-19 05:16:27,650 epoch 7 - iter 40/202 - loss 1.10771850\n","2019-06-19 05:16:49,754 epoch 7 - iter 60/202 - loss 1.13116379\n","2019-06-19 05:17:07,805 epoch 7 - iter 80/202 - loss 1.14348570\n","2019-06-19 05:17:27,785 epoch 7 - iter 100/202 - loss 1.12966653\n","2019-06-19 05:17:47,377 epoch 7 - iter 120/202 - loss 1.16047820\n","2019-06-19 05:18:10,218 epoch 7 - iter 140/202 - loss 1.17864405\n","2019-06-19 05:18:33,515 epoch 7 - iter 160/202 - loss 1.16244437\n","2019-06-19 05:18:53,107 epoch 7 - iter 180/202 - loss 1.16049954\n","2019-06-19 05:19:09,404 epoch 7 - iter 200/202 - loss 1.16725755\n","2019-06-19 05:19:10,574 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:19:10,578 EPOCH 7 done: loss 1.1640 - lr 0.0500 - bad epochs 1\n","2019-06-19 05:19:31,446 DEV : loss 0.856465756893158 - score 0.4583\n","2019-06-19 05:20:38,271 TEST : loss 1.1309475898742676 - score 0.4383\n","2019-06-19 05:20:38,279 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:20:39,938 epoch 8 - iter 0/202 - loss 1.77057004\n","2019-06-19 05:21:00,177 epoch 8 - iter 20/202 - loss 1.02728372\n","2019-06-19 05:21:21,481 epoch 8 - iter 40/202 - loss 1.11799978\n","2019-06-19 05:21:42,195 epoch 8 - iter 60/202 - loss 1.19480618\n","2019-06-19 05:22:02,536 epoch 8 - iter 80/202 - loss 1.17730933\n","2019-06-19 05:22:23,006 epoch 8 - iter 100/202 - loss 1.20168062\n","2019-06-19 05:22:39,134 epoch 8 - iter 120/202 - loss 1.16540466\n","2019-06-19 05:23:02,879 epoch 8 - iter 140/202 - loss 1.16882459\n","2019-06-19 05:23:27,024 epoch 8 - iter 160/202 - loss 1.16560489\n","2019-06-19 05:23:44,681 epoch 8 - iter 180/202 - loss 1.16834296\n","2019-06-19 05:24:05,981 epoch 8 - iter 200/202 - loss 1.14863389\n","2019-06-19 05:24:07,110 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:24:07,111 EPOCH 8 done: loss 1.1441 - lr 0.0500 - bad epochs 2\n","2019-06-19 05:24:25,779 DEV : loss 0.8354869484901428 - score 0.542\n","2019-06-19 05:25:34,063 TEST : loss 1.108156681060791 - score 0.5044\n","2019-06-19 05:25:44,041 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:25:45,794 epoch 9 - iter 0/202 - loss 0.79373085\n","2019-06-19 05:26:06,715 epoch 9 - iter 20/202 - loss 1.07562503\n","2019-06-19 05:26:31,106 epoch 9 - iter 40/202 - loss 1.10301062\n","2019-06-19 05:26:50,754 epoch 9 - iter 60/202 - loss 1.12824246\n","2019-06-19 05:27:08,461 epoch 9 - iter 80/202 - loss 1.12925480\n","2019-06-19 05:27:26,916 epoch 9 - iter 100/202 - loss 1.10880958\n","2019-06-19 05:27:49,056 epoch 9 - iter 120/202 - loss 1.10919854\n","2019-06-19 05:28:12,464 epoch 9 - iter 140/202 - loss 1.11949201\n","2019-06-19 05:28:32,844 epoch 9 - iter 160/202 - loss 1.11566175\n","2019-06-19 05:28:50,329 epoch 9 - iter 180/202 - loss 1.11388847\n","2019-06-19 05:29:10,542 epoch 9 - iter 200/202 - loss 1.11481360\n","2019-06-19 05:29:11,933 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:29:11,934 EPOCH 9 done: loss 1.1174 - lr 0.0500 - bad epochs 0\n","2019-06-19 05:29:30,467 DEV : loss 0.8407859802246094 - score 0.6327\n","2019-06-19 05:30:37,524 TEST : loss 1.06358802318573 - score 0.6326\n","2019-06-19 05:30:48,673 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:30:50,500 epoch 10 - iter 0/202 - loss 0.46625549\n","2019-06-19 05:31:09,795 epoch 10 - iter 20/202 - loss 1.10235763\n","2019-06-19 05:31:30,363 epoch 10 - iter 40/202 - loss 1.11107835\n","2019-06-19 05:31:52,871 epoch 10 - iter 60/202 - loss 1.10313736\n","2019-06-19 05:32:14,435 epoch 10 - iter 80/202 - loss 1.11047553\n","2019-06-19 05:32:36,694 epoch 10 - iter 100/202 - loss 1.09556977\n","2019-06-19 05:32:54,365 epoch 10 - iter 120/202 - loss 1.10499068\n","2019-06-19 05:33:12,158 epoch 10 - iter 140/202 - loss 1.12770120\n","2019-06-19 05:33:35,926 epoch 10 - iter 160/202 - loss 1.12589653\n","2019-06-19 05:33:53,767 epoch 10 - iter 180/202 - loss 1.09653643\n","2019-06-19 05:34:13,753 epoch 10 - iter 200/202 - loss 1.10091530\n","2019-06-19 05:34:14,810 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:34:14,812 EPOCH 10 done: loss 1.0990 - lr 0.0500 - bad epochs 0\n","2019-06-19 05:34:35,283 DEV : loss 0.8071733713150024 - score 0.566\n","2019-06-19 05:35:42,084 TEST : loss 1.053078532218933 - score 0.576\n","2019-06-19 05:35:42,092 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:35:43,935 epoch 11 - iter 0/202 - loss 1.44197786\n","2019-06-19 05:36:05,307 epoch 11 - iter 20/202 - loss 1.13543982\n","2019-06-19 05:36:29,825 epoch 11 - iter 40/202 - loss 1.04737835\n","2019-06-19 05:36:46,454 epoch 11 - iter 60/202 - loss 1.00002017\n","2019-06-19 05:37:07,533 epoch 11 - iter 80/202 - loss 0.98369049\n","2019-06-19 05:37:32,392 epoch 11 - iter 100/202 - loss 1.01898583\n","2019-06-19 05:37:52,780 epoch 11 - iter 120/202 - loss 1.04315092\n","2019-06-19 05:38:10,287 epoch 11 - iter 140/202 - loss 1.04645788\n","2019-06-19 05:38:28,836 epoch 11 - iter 160/202 - loss 1.04506932\n","2019-06-19 05:38:49,630 epoch 11 - iter 180/202 - loss 1.05964947\n","2019-06-19 05:39:08,900 epoch 11 - iter 200/202 - loss 1.05855298\n","2019-06-19 05:39:10,021 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:39:10,023 EPOCH 11 done: loss 1.0565 - lr 0.0500 - bad epochs 1\n","2019-06-19 05:39:28,666 DEV : loss 0.7825814485549927 - score 0.5628\n","2019-06-19 05:40:37,069 TEST : loss 1.0268170833587646 - score 0.5737\n","2019-06-19 05:40:37,077 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:40:39,210 epoch 12 - iter 0/202 - loss 2.03249931\n","2019-06-19 05:40:58,544 epoch 12 - iter 20/202 - loss 1.04875343\n","2019-06-19 05:41:19,789 epoch 12 - iter 40/202 - loss 1.07447042\n","2019-06-19 05:41:44,332 epoch 12 - iter 60/202 - loss 0.99837078\n","2019-06-19 05:42:03,515 epoch 12 - iter 80/202 - loss 1.03440221\n","2019-06-19 05:42:29,160 epoch 12 - iter 100/202 - loss 1.03927153\n","2019-06-19 05:42:50,534 epoch 12 - iter 120/202 - loss 1.05442463\n","2019-06-19 05:43:10,836 epoch 12 - iter 140/202 - loss 1.06172672\n","2019-06-19 05:43:32,131 epoch 12 - iter 160/202 - loss 1.06181859\n","2019-06-19 05:43:47,951 epoch 12 - iter 180/202 - loss 1.05862080\n","2019-06-19 05:44:04,281 epoch 12 - iter 200/202 - loss 1.05003808\n","2019-06-19 05:44:05,651 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:44:05,653 EPOCH 12 done: loss 1.0524 - lr 0.0500 - bad epochs 2\n","2019-06-19 05:44:26,319 DEV : loss 0.7814131379127502 - score 0.5282\n","2019-06-19 05:45:33,247 TEST : loss 1.0177884101867676 - score 0.5371\n","2019-06-19 05:45:33,255 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:45:35,538 epoch 13 - iter 0/202 - loss 1.40608883\n","2019-06-19 05:46:02,133 epoch 13 - iter 20/202 - loss 0.99317213\n","2019-06-19 05:46:19,142 epoch 13 - iter 40/202 - loss 1.02831485\n","2019-06-19 05:46:38,119 epoch 13 - iter 60/202 - loss 1.02068150\n","2019-06-19 05:46:59,422 epoch 13 - iter 80/202 - loss 1.01671701\n","2019-06-19 05:47:17,724 epoch 13 - iter 100/202 - loss 1.00984014\n","2019-06-19 05:47:36,913 epoch 13 - iter 120/202 - loss 1.03505584\n","2019-06-19 05:47:56,993 epoch 13 - iter 140/202 - loss 1.04652580\n","2019-06-19 05:48:15,619 epoch 13 - iter 160/202 - loss 1.03825376\n","2019-06-19 05:48:40,751 epoch 13 - iter 180/202 - loss 1.03437380\n","2019-06-19 05:49:00,467 epoch 13 - iter 200/202 - loss 1.03351378\n","2019-06-19 05:49:01,729 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:49:01,731 EPOCH 13 done: loss 1.0341 - lr 0.0500 - bad epochs 3\n","2019-06-19 05:49:20,325 DEV : loss 0.7816867232322693 - score 0.6494\n","2019-06-19 05:50:28,301 TEST : loss 0.9777713418006897 - score 0.6622\n","2019-06-19 05:50:38,647 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:50:42,763 epoch 14 - iter 0/202 - loss 1.34371555\n","2019-06-19 05:51:00,090 epoch 14 - iter 20/202 - loss 1.02880598\n","2019-06-19 05:51:25,722 epoch 14 - iter 40/202 - loss 1.06844313\n","2019-06-19 05:51:44,457 epoch 14 - iter 60/202 - loss 1.02252297\n","2019-06-19 05:52:06,891 epoch 14 - iter 80/202 - loss 1.00326669\n","2019-06-19 05:52:25,960 epoch 14 - iter 100/202 - loss 1.02073087\n","2019-06-19 05:52:46,066 epoch 14 - iter 120/202 - loss 1.01699281\n","2019-06-19 05:53:09,264 epoch 14 - iter 140/202 - loss 1.02349834\n","2019-06-19 05:53:25,735 epoch 14 - iter 160/202 - loss 1.01421777\n","2019-06-19 05:53:42,523 epoch 14 - iter 180/202 - loss 1.01691578\n","2019-06-19 05:54:05,169 epoch 14 - iter 200/202 - loss 1.02034417\n","2019-06-19 05:54:06,353 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:54:06,358 EPOCH 14 done: loss 1.0187 - lr 0.0500 - bad epochs 0\n","2019-06-19 05:54:25,007 DEV : loss 0.7784923315048218 - score 0.6584\n","2019-06-19 05:55:31,661 TEST : loss 0.9789133071899414 - score 0.6606\n","2019-06-19 05:55:42,757 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 05:55:45,224 epoch 15 - iter 0/202 - loss 0.81392777\n","2019-06-19 05:56:06,598 epoch 15 - iter 20/202 - loss 0.99319048\n","2019-06-19 05:56:26,711 epoch 15 - iter 40/202 - loss 1.05581460\n","2019-06-19 05:56:49,987 epoch 15 - iter 60/202 - loss 0.97505025\n","2019-06-19 05:57:07,442 epoch 15 - iter 80/202 - loss 0.98478236\n","2019-06-19 05:57:25,596 epoch 15 - iter 100/202 - loss 0.95239438\n","2019-06-19 05:57:48,234 epoch 15 - iter 120/202 - loss 0.97664372\n","2019-06-19 05:58:06,991 epoch 15 - iter 140/202 - loss 0.97389264\n","2019-06-19 05:58:26,879 epoch 15 - iter 160/202 - loss 0.98215229\n","2019-06-19 05:58:49,052 epoch 15 - iter 180/202 - loss 0.98502847\n","2019-06-19 05:59:06,979 epoch 15 - iter 200/202 - loss 0.98559745\n","2019-06-19 05:59:08,255 ----------------------------------------------------------------------------------------------------\n","2019-06-19 05:59:08,256 EPOCH 15 done: loss 0.9814 - lr 0.0500 - bad epochs 0\n","2019-06-19 05:59:28,643 DEV : loss 0.7740475535392761 - score 0.6116\n","2019-06-19 06:00:34,881 TEST : loss 0.9909825921058655 - score 0.5838\n","2019-06-19 06:00:34,888 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:00:37,247 epoch 16 - iter 0/202 - loss 0.69679719\n","2019-06-19 06:00:55,942 epoch 16 - iter 20/202 - loss 0.96038523\n","2019-06-19 06:01:17,941 epoch 16 - iter 40/202 - loss 0.89717309\n","2019-06-19 06:01:41,527 epoch 16 - iter 60/202 - loss 0.93929630\n","2019-06-19 06:02:03,062 epoch 16 - iter 80/202 - loss 0.93457873\n","2019-06-19 06:02:25,715 epoch 16 - iter 100/202 - loss 0.95351308\n","2019-06-19 06:02:43,903 epoch 16 - iter 120/202 - loss 0.98255611\n","2019-06-19 06:03:01,694 epoch 16 - iter 140/202 - loss 0.95004005\n","2019-06-19 06:03:22,081 epoch 16 - iter 160/202 - loss 0.97535223\n","2019-06-19 06:03:40,035 epoch 16 - iter 180/202 - loss 0.97342176\n","2019-06-19 06:03:59,509 epoch 16 - iter 200/202 - loss 0.97879006\n","2019-06-19 06:04:00,661 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:04:00,665 EPOCH 16 done: loss 0.9744 - lr 0.0500 - bad epochs 1\n","2019-06-19 06:04:21,444 DEV : loss 0.743556559085846 - score 0.5346\n","2019-06-19 06:05:28,223 TEST : loss 0.9349638819694519 - score 0.5899\n","2019-06-19 06:05:28,232 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:05:30,197 epoch 17 - iter 0/202 - loss 1.44993544\n","2019-06-19 06:05:55,122 epoch 17 - iter 20/202 - loss 0.98492761\n","2019-06-19 06:06:15,406 epoch 17 - iter 40/202 - loss 0.91429145\n","2019-06-19 06:06:37,436 epoch 17 - iter 60/202 - loss 0.93779768\n","2019-06-19 06:06:59,821 epoch 17 - iter 80/202 - loss 0.96833072\n","2019-06-19 06:07:16,875 epoch 17 - iter 100/202 - loss 0.94247433\n","2019-06-19 06:07:38,604 epoch 17 - iter 120/202 - loss 0.96974261\n","2019-06-19 06:07:54,832 epoch 17 - iter 140/202 - loss 0.96479285\n","2019-06-19 06:08:19,616 epoch 17 - iter 160/202 - loss 0.95219727\n","2019-06-19 06:08:39,936 epoch 17 - iter 180/202 - loss 0.95005462\n","2019-06-19 06:08:56,435 epoch 17 - iter 200/202 - loss 0.94911553\n","2019-06-19 06:08:58,249 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:08:58,251 EPOCH 17 done: loss 0.9484 - lr 0.0500 - bad epochs 2\n","2019-06-19 06:09:18,840 DEV : loss 0.7441307902336121 - score 0.6776\n","2019-06-19 06:10:25,292 TEST : loss 0.9417612552642822 - score 0.6608\n","2019-06-19 06:10:35,342 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:10:37,284 epoch 18 - iter 0/202 - loss 1.28825140\n","2019-06-19 06:10:58,226 epoch 18 - iter 20/202 - loss 0.88380665\n","2019-06-19 06:11:22,935 epoch 18 - iter 40/202 - loss 0.89246774\n","2019-06-19 06:11:40,729 epoch 18 - iter 60/202 - loss 0.90690639\n","2019-06-19 06:11:58,232 epoch 18 - iter 80/202 - loss 0.90030734\n","2019-06-19 06:12:19,915 epoch 18 - iter 100/202 - loss 0.92022489\n","2019-06-19 06:12:39,983 epoch 18 - iter 120/202 - loss 0.91208108\n","2019-06-19 06:13:01,398 epoch 18 - iter 140/202 - loss 0.91474414\n","2019-06-19 06:13:21,370 epoch 18 - iter 160/202 - loss 0.91657052\n","2019-06-19 06:13:40,902 epoch 18 - iter 180/202 - loss 0.91984396\n","2019-06-19 06:14:01,908 epoch 18 - iter 200/202 - loss 0.93624915\n","2019-06-19 06:14:03,116 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:14:03,118 EPOCH 18 done: loss 0.9476 - lr 0.0500 - bad epochs 0\n","2019-06-19 06:14:21,672 DEV : loss 0.7783689498901367 - score 0.4414\n","2019-06-19 06:15:29,191 TEST : loss 0.979335606098175 - score 0.4844\n","2019-06-19 06:15:29,199 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:15:30,960 epoch 19 - iter 0/202 - loss 0.47201407\n","2019-06-19 06:15:52,877 epoch 19 - iter 20/202 - loss 0.94193620\n","2019-06-19 06:16:13,594 epoch 19 - iter 40/202 - loss 0.91508163\n","2019-06-19 06:16:36,342 epoch 19 - iter 60/202 - loss 0.89495172\n","2019-06-19 06:16:56,695 epoch 19 - iter 80/202 - loss 0.86995260\n","2019-06-19 06:17:18,380 epoch 19 - iter 100/202 - loss 0.88398867\n","2019-06-19 06:17:39,190 epoch 19 - iter 120/202 - loss 0.90303338\n","2019-06-19 06:17:59,528 epoch 19 - iter 140/202 - loss 0.91326350\n","2019-06-19 06:18:20,421 epoch 19 - iter 160/202 - loss 0.91703291\n","2019-06-19 06:18:38,175 epoch 19 - iter 180/202 - loss 0.91062123\n","2019-06-19 06:18:54,805 epoch 19 - iter 200/202 - loss 0.90774857\n","2019-06-19 06:18:55,916 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:18:55,920 EPOCH 19 done: loss 0.9039 - lr 0.0500 - bad epochs 1\n","2019-06-19 06:19:16,426 DEV : loss 0.6986492872238159 - score 0.6788\n","2019-06-19 06:20:22,956 TEST : loss 0.8879653811454773 - score 0.6859\n","2019-06-19 06:20:32,938 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:20:34,836 epoch 20 - iter 0/202 - loss 1.81768239\n","2019-06-19 06:20:58,118 epoch 20 - iter 20/202 - loss 1.08383398\n","2019-06-19 06:21:15,455 epoch 20 - iter 40/202 - loss 0.97171280\n","2019-06-19 06:21:38,382 epoch 20 - iter 60/202 - loss 0.93371807\n","2019-06-19 06:21:57,159 epoch 20 - iter 80/202 - loss 0.89490650\n","2019-06-19 06:22:14,734 epoch 20 - iter 100/202 - loss 0.88453085\n","2019-06-19 06:22:40,472 epoch 20 - iter 120/202 - loss 0.89065937\n","2019-06-19 06:22:59,088 epoch 20 - iter 140/202 - loss 0.88929608\n","2019-06-19 06:23:15,189 epoch 20 - iter 160/202 - loss 0.88069308\n","2019-06-19 06:23:38,246 epoch 20 - iter 180/202 - loss 0.88436838\n","2019-06-19 06:23:59,412 epoch 20 - iter 200/202 - loss 0.89369934\n","2019-06-19 06:24:00,506 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:24:00,508 EPOCH 20 done: loss 0.8933 - lr 0.0500 - bad epochs 0\n","2019-06-19 06:24:19,141 DEV : loss 0.7238327860832214 - score 0.6073\n","2019-06-19 06:25:26,824 TEST : loss 0.9102294445037842 - score 0.6277\n","2019-06-19 06:25:26,832 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:25:28,721 epoch 21 - iter 0/202 - loss 1.21925688\n","2019-06-19 06:25:51,396 epoch 21 - iter 20/202 - loss 0.89634806\n","2019-06-19 06:26:09,854 epoch 21 - iter 40/202 - loss 0.86036046\n","2019-06-19 06:26:27,912 epoch 21 - iter 60/202 - loss 0.85522461\n","2019-06-19 06:26:51,678 epoch 21 - iter 80/202 - loss 0.84431891\n","2019-06-19 06:27:15,055 epoch 21 - iter 100/202 - loss 0.85219563\n","2019-06-19 06:27:32,694 epoch 21 - iter 120/202 - loss 0.85418704\n","2019-06-19 06:27:53,030 epoch 21 - iter 140/202 - loss 0.86082073\n","2019-06-19 06:28:14,438 epoch 21 - iter 160/202 - loss 0.86400774\n","2019-06-19 06:28:32,788 epoch 21 - iter 180/202 - loss 0.86877108\n","2019-06-19 06:28:51,809 epoch 21 - iter 200/202 - loss 0.87594127\n","2019-06-19 06:28:53,010 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:28:53,012 EPOCH 21 done: loss 0.8752 - lr 0.0500 - bad epochs 1\n","2019-06-19 06:29:13,553 DEV : loss 0.7053269147872925 - score 0.6075\n","2019-06-19 06:30:20,226 TEST : loss 0.904254674911499 - score 0.5867\n","2019-06-19 06:30:20,234 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:30:21,937 epoch 22 - iter 0/202 - loss 0.48299450\n","2019-06-19 06:30:44,480 epoch 22 - iter 20/202 - loss 0.86262034\n","2019-06-19 06:31:00,962 epoch 22 - iter 40/202 - loss 0.82274110\n","2019-06-19 06:31:16,045 epoch 22 - iter 60/202 - loss 0.82001617\n","2019-06-19 06:31:33,266 epoch 22 - iter 80/202 - loss 0.82271371\n","2019-06-19 06:31:54,464 epoch 22 - iter 100/202 - loss 0.84233589\n","2019-06-19 06:32:16,086 epoch 22 - iter 120/202 - loss 0.84310331\n","2019-06-19 06:32:40,740 epoch 22 - iter 140/202 - loss 0.85999993\n","2019-06-19 06:33:00,122 epoch 22 - iter 160/202 - loss 0.86499787\n","2019-06-19 06:33:24,986 epoch 22 - iter 180/202 - loss 0.84912766\n","2019-06-19 06:33:46,038 epoch 22 - iter 200/202 - loss 0.85830456\n","2019-06-19 06:33:47,343 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:33:47,345 EPOCH 22 done: loss 0.8569 - lr 0.0500 - bad epochs 2\n","2019-06-19 06:34:05,939 DEV : loss 0.7406256198883057 - score 0.532\n","2019-06-19 06:35:14,136 TEST : loss 0.9433594942092896 - score 0.5554\n","2019-06-19 06:35:14,145 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:35:16,545 epoch 23 - iter 0/202 - loss 1.05333519\n","2019-06-19 06:35:36,347 epoch 23 - iter 20/202 - loss 0.79975834\n","2019-06-19 06:35:58,225 epoch 23 - iter 40/202 - loss 0.81511297\n","2019-06-19 06:36:18,108 epoch 23 - iter 60/202 - loss 0.79999005\n","2019-06-19 06:36:37,176 epoch 23 - iter 80/202 - loss 0.84182994\n","2019-06-19 06:36:56,855 epoch 23 - iter 100/202 - loss 0.84274133\n","2019-06-19 06:37:19,070 epoch 23 - iter 120/202 - loss 0.85833620\n","2019-06-19 06:37:39,414 epoch 23 - iter 140/202 - loss 0.83855421\n","2019-06-19 06:37:59,707 epoch 23 - iter 160/202 - loss 0.83880067\n","2019-06-19 06:38:18,721 epoch 23 - iter 180/202 - loss 0.83982811\n","2019-06-19 06:38:39,147 epoch 23 - iter 200/202 - loss 0.82857140\n","2019-06-19 06:38:40,277 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:38:40,279 EPOCH 23 done: loss 0.8307 - lr 0.0500 - bad epochs 3\n","2019-06-19 06:38:58,839 DEV : loss 0.6858723163604736 - score 0.6183\n","2019-06-19 06:40:05,481 TEST : loss 0.8689767122268677 - score 0.6446\n","Epoch    22: reducing learning rate of group 0 to 2.5000e-02.\n","2019-06-19 06:40:05,491 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:40:07,796 epoch 24 - iter 0/202 - loss 1.16486108\n","2019-06-19 06:40:32,115 epoch 24 - iter 20/202 - loss 0.82732925\n","2019-06-19 06:40:48,318 epoch 24 - iter 40/202 - loss 0.79478339\n","2019-06-19 06:41:07,651 epoch 24 - iter 60/202 - loss 0.76091073\n","2019-06-19 06:41:32,380 epoch 24 - iter 80/202 - loss 0.78114310\n","2019-06-19 06:41:54,340 epoch 24 - iter 100/202 - loss 0.79210881\n","2019-06-19 06:42:14,501 epoch 24 - iter 120/202 - loss 0.80626670\n","2019-06-19 06:42:31,685 epoch 24 - iter 140/202 - loss 0.84053436\n","2019-06-19 06:42:55,697 epoch 24 - iter 160/202 - loss 0.83458310\n","2019-06-19 06:43:14,700 epoch 24 - iter 180/202 - loss 0.83416877\n","2019-06-19 06:43:32,344 epoch 24 - iter 200/202 - loss 0.81725994\n","2019-06-19 06:43:33,489 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:43:33,494 EPOCH 24 done: loss 0.8137 - lr 0.0250 - bad epochs 0\n","2019-06-19 06:43:52,110 DEV : loss 0.6529816389083862 - score 0.7066\n","2019-06-19 06:44:59,941 TEST : loss 0.8342652916908264 - score 0.7158\n","2019-06-19 06:45:10,006 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:45:11,805 epoch 25 - iter 0/202 - loss 0.72243500\n","2019-06-19 06:45:35,267 epoch 25 - iter 20/202 - loss 0.91629555\n","2019-06-19 06:45:54,292 epoch 25 - iter 40/202 - loss 0.78714429\n","2019-06-19 06:46:16,839 epoch 25 - iter 60/202 - loss 0.78842785\n","2019-06-19 06:46:37,428 epoch 25 - iter 80/202 - loss 0.77643173\n","2019-06-19 06:46:58,889 epoch 25 - iter 100/202 - loss 0.77737887\n","2019-06-19 06:47:16,881 epoch 25 - iter 120/202 - loss 0.79131665\n","2019-06-19 06:47:38,045 epoch 25 - iter 140/202 - loss 0.78190335\n","2019-06-19 06:47:57,204 epoch 25 - iter 160/202 - loss 0.76220525\n","2019-06-19 06:48:17,206 epoch 25 - iter 180/202 - loss 0.76526123\n","2019-06-19 06:48:36,956 epoch 25 - iter 200/202 - loss 0.77406604\n","2019-06-19 06:48:38,407 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:48:38,409 EPOCH 25 done: loss 0.7703 - lr 0.0250 - bad epochs 0\n","2019-06-19 06:48:57,029 DEV : loss 0.6715787053108215 - score 0.6785\n","2019-06-19 06:50:05,107 TEST : loss 0.8440614342689514 - score 0.6949\n","2019-06-19 06:50:05,122 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:50:06,843 epoch 26 - iter 0/202 - loss 0.86618513\n","2019-06-19 06:50:26,742 epoch 26 - iter 20/202 - loss 0.96487794\n","2019-06-19 06:50:48,199 epoch 26 - iter 40/202 - loss 0.79206554\n","2019-06-19 06:51:08,204 epoch 26 - iter 60/202 - loss 0.78479348\n","2019-06-19 06:51:31,017 epoch 26 - iter 80/202 - loss 0.77804641\n","2019-06-19 06:51:52,190 epoch 26 - iter 100/202 - loss 0.81733773\n","2019-06-19 06:52:13,367 epoch 26 - iter 120/202 - loss 0.80070304\n","2019-06-19 06:52:31,262 epoch 26 - iter 140/202 - loss 0.78507061\n","2019-06-19 06:52:50,615 epoch 26 - iter 160/202 - loss 0.78474335\n","2019-06-19 06:53:14,823 epoch 26 - iter 180/202 - loss 0.77997675\n","2019-06-19 06:53:33,658 epoch 26 - iter 200/202 - loss 0.78396489\n","2019-06-19 06:53:34,937 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:53:34,938 EPOCH 26 done: loss 0.7820 - lr 0.0250 - bad epochs 1\n","2019-06-19 06:53:55,542 DEV : loss 0.6535578966140747 - score 0.661\n","2019-06-19 06:55:02,127 TEST : loss 0.8185526728630066 - score 0.6781\n","2019-06-19 06:55:02,138 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 06:55:04,061 epoch 27 - iter 0/202 - loss 0.78093898\n","2019-06-19 06:55:28,359 epoch 27 - iter 20/202 - loss 1.01875035\n","2019-06-19 06:55:49,341 epoch 27 - iter 40/202 - loss 0.90957295\n","2019-06-19 06:56:06,557 epoch 27 - iter 60/202 - loss 0.86613833\n","2019-06-19 06:56:27,344 epoch 27 - iter 80/202 - loss 0.81655485\n","2019-06-19 06:56:51,959 epoch 27 - iter 100/202 - loss 0.81779183\n","2019-06-19 06:57:14,256 epoch 27 - iter 120/202 - loss 0.79794845\n","2019-06-19 06:57:33,427 epoch 27 - iter 140/202 - loss 0.79427594\n","2019-06-19 06:57:50,402 epoch 27 - iter 160/202 - loss 0.78043089\n","2019-06-19 06:58:12,696 epoch 27 - iter 180/202 - loss 0.77085227\n","2019-06-19 06:58:31,255 epoch 27 - iter 200/202 - loss 0.75687217\n","2019-06-19 06:58:32,364 ----------------------------------------------------------------------------------------------------\n","2019-06-19 06:58:32,366 EPOCH 27 done: loss 0.7534 - lr 0.0250 - bad epochs 2\n","2019-06-19 06:58:50,958 DEV : loss 0.635265588760376 - score 0.7056\n","2019-06-19 06:59:59,021 TEST : loss 0.8133651614189148 - score 0.7158\n","2019-06-19 06:59:59,030 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:00:00,559 epoch 28 - iter 0/202 - loss 0.70346737\n","2019-06-19 07:00:22,356 epoch 28 - iter 20/202 - loss 0.70774583\n","2019-06-19 07:00:44,819 epoch 28 - iter 40/202 - loss 0.76942829\n","2019-06-19 07:01:04,512 epoch 28 - iter 60/202 - loss 0.75182309\n","2019-06-19 07:01:25,872 epoch 28 - iter 80/202 - loss 0.74182525\n","2019-06-19 07:01:48,056 epoch 28 - iter 100/202 - loss 0.74203892\n","2019-06-19 07:02:06,514 epoch 28 - iter 120/202 - loss 0.72817126\n","2019-06-19 07:02:28,863 epoch 28 - iter 140/202 - loss 0.72710400\n","2019-06-19 07:02:48,940 epoch 28 - iter 160/202 - loss 0.73934071\n","2019-06-19 07:03:07,519 epoch 28 - iter 180/202 - loss 0.74431428\n","2019-06-19 07:03:26,110 epoch 28 - iter 200/202 - loss 0.74599744\n","2019-06-19 07:03:27,265 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:03:27,267 EPOCH 28 done: loss 0.7446 - lr 0.0250 - bad epochs 3\n","2019-06-19 07:03:47,907 DEV : loss 0.6300849914550781 - score 0.7061\n","2019-06-19 07:04:54,713 TEST : loss 0.7928274869918823 - score 0.7256\n","Epoch    27: reducing learning rate of group 0 to 1.2500e-02.\n","2019-06-19 07:04:54,722 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:04:56,312 epoch 29 - iter 0/202 - loss 0.11773284\n","2019-06-19 07:05:20,769 epoch 29 - iter 20/202 - loss 0.90143129\n","2019-06-19 07:05:37,089 epoch 29 - iter 40/202 - loss 0.74637279\n","2019-06-19 07:05:57,376 epoch 29 - iter 60/202 - loss 0.73839434\n","2019-06-19 07:06:16,100 epoch 29 - iter 80/202 - loss 0.71957347\n","2019-06-19 07:06:37,311 epoch 29 - iter 100/202 - loss 0.71680604\n","2019-06-19 07:07:01,763 epoch 29 - iter 120/202 - loss 0.72729510\n","2019-06-19 07:07:20,591 epoch 29 - iter 140/202 - loss 0.72820332\n","2019-06-19 07:07:41,901 epoch 29 - iter 160/202 - loss 0.74000663\n","2019-06-19 07:07:59,121 epoch 29 - iter 180/202 - loss 0.73361040\n","2019-06-19 07:08:18,710 epoch 29 - iter 200/202 - loss 0.72999634\n","2019-06-19 07:08:20,019 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:08:20,024 EPOCH 29 done: loss 0.7314 - lr 0.0125 - bad epochs 0\n","2019-06-19 07:08:38,905 DEV : loss 0.6130843758583069 - score 0.7029\n","2019-06-19 07:09:47,080 TEST : loss 0.7776098251342773 - score 0.7234\n","2019-06-19 07:09:47,087 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:09:48,930 epoch 30 - iter 0/202 - loss 0.74036598\n","2019-06-19 07:10:09,268 epoch 30 - iter 20/202 - loss 0.66234161\n","2019-06-19 07:10:27,436 epoch 30 - iter 40/202 - loss 0.71412333\n","2019-06-19 07:10:50,322 epoch 30 - iter 60/202 - loss 0.69142776\n","2019-06-19 07:11:07,818 epoch 30 - iter 80/202 - loss 0.69556862\n","2019-06-19 07:11:30,205 epoch 30 - iter 100/202 - loss 0.69905975\n","2019-06-19 07:11:54,208 epoch 30 - iter 120/202 - loss 0.70500830\n","2019-06-19 07:12:14,301 epoch 30 - iter 140/202 - loss 0.71061045\n","2019-06-19 07:12:32,329 epoch 30 - iter 160/202 - loss 0.72241015\n","2019-06-19 07:12:54,315 epoch 30 - iter 180/202 - loss 0.72262409\n","2019-06-19 07:13:13,211 epoch 30 - iter 200/202 - loss 0.71637314\n","2019-06-19 07:13:14,658 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:13:14,660 EPOCH 30 done: loss 0.7138 - lr 0.0125 - bad epochs 1\n","2019-06-19 07:13:35,329 DEV : loss 0.6158787608146667 - score 0.704\n","2019-06-19 07:14:41,865 TEST : loss 0.7775434255599976 - score 0.7389\n","2019-06-19 07:14:41,875 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:14:43,670 epoch 31 - iter 0/202 - loss 1.32483411\n","2019-06-19 07:15:03,676 epoch 31 - iter 20/202 - loss 0.73240592\n","2019-06-19 07:15:22,780 epoch 31 - iter 40/202 - loss 0.75531929\n","2019-06-19 07:15:44,614 epoch 31 - iter 60/202 - loss 0.70194697\n","2019-06-19 07:16:03,720 epoch 31 - iter 80/202 - loss 0.66624466\n","2019-06-19 07:16:22,265 epoch 31 - iter 100/202 - loss 0.66565942\n","2019-06-19 07:16:41,355 epoch 31 - iter 120/202 - loss 0.66782061\n","2019-06-19 07:17:01,575 epoch 31 - iter 140/202 - loss 0.67362620\n","2019-06-19 07:17:23,570 epoch 31 - iter 160/202 - loss 0.68465044\n","2019-06-19 07:17:48,968 epoch 31 - iter 180/202 - loss 0.69531911\n","2019-06-19 07:18:09,528 epoch 31 - iter 200/202 - loss 0.69873150\n","2019-06-19 07:18:10,628 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:18:10,630 EPOCH 31 done: loss 0.6986 - lr 0.0125 - bad epochs 2\n","2019-06-19 07:18:29,229 DEV : loss 0.6049084067344666 - score 0.7133\n","2019-06-19 07:19:37,653 TEST : loss 0.7667676210403442 - score 0.7324\n","2019-06-19 07:19:47,692 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:19:50,052 epoch 32 - iter 0/202 - loss 0.55025887\n","2019-06-19 07:20:09,014 epoch 32 - iter 20/202 - loss 0.78417799\n","2019-06-19 07:20:30,453 epoch 32 - iter 40/202 - loss 0.74765450\n","2019-06-19 07:20:50,824 epoch 32 - iter 60/202 - loss 0.76595888\n","2019-06-19 07:21:09,230 epoch 32 - iter 80/202 - loss 0.75455533\n","2019-06-19 07:21:28,597 epoch 32 - iter 100/202 - loss 0.73530323\n","2019-06-19 07:21:48,815 epoch 32 - iter 120/202 - loss 0.73260755\n","2019-06-19 07:22:12,789 epoch 32 - iter 140/202 - loss 0.71349020\n","2019-06-19 07:22:31,330 epoch 32 - iter 160/202 - loss 0.71408099\n","2019-06-19 07:22:51,664 epoch 32 - iter 180/202 - loss 0.70930262\n","2019-06-19 07:23:12,215 epoch 32 - iter 200/202 - loss 0.71673658\n","2019-06-19 07:23:13,371 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:23:13,372 EPOCH 32 done: loss 0.7136 - lr 0.0125 - bad epochs 0\n","2019-06-19 07:23:31,999 DEV : loss 0.6016934514045715 - score 0.712\n","2019-06-19 07:24:38,491 TEST : loss 0.7709894180297852 - score 0.735\n","2019-06-19 07:24:38,498 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:24:40,690 epoch 33 - iter 0/202 - loss 0.58388186\n","2019-06-19 07:25:03,931 epoch 33 - iter 20/202 - loss 0.64719708\n","2019-06-19 07:25:21,774 epoch 33 - iter 40/202 - loss 0.69621827\n","2019-06-19 07:25:46,412 epoch 33 - iter 60/202 - loss 0.68799034\n","2019-06-19 07:26:05,005 epoch 33 - iter 80/202 - loss 0.68871879\n","2019-06-19 07:26:25,388 epoch 33 - iter 100/202 - loss 0.69964383\n","2019-06-19 07:26:47,619 epoch 33 - iter 120/202 - loss 0.70819967\n","2019-06-19 07:27:03,196 epoch 33 - iter 140/202 - loss 0.70089935\n","2019-06-19 07:27:22,796 epoch 33 - iter 160/202 - loss 0.71349151\n","2019-06-19 07:27:44,639 epoch 33 - iter 180/202 - loss 0.70442442\n","2019-06-19 07:28:02,976 epoch 33 - iter 200/202 - loss 0.68171352\n","2019-06-19 07:28:04,281 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:28:04,282 EPOCH 33 done: loss 0.6803 - lr 0.0125 - bad epochs 1\n","2019-06-19 07:28:25,022 DEV : loss 0.6128799915313721 - score 0.7146\n","2019-06-19 07:29:31,853 TEST : loss 0.7729553580284119 - score 0.7366\n","2019-06-19 07:29:41,953 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:29:44,486 epoch 34 - iter 0/202 - loss 0.83734500\n","2019-06-19 07:30:08,928 epoch 34 - iter 20/202 - loss 0.70000701\n","2019-06-19 07:30:29,157 epoch 34 - iter 40/202 - loss 0.63449984\n","2019-06-19 07:30:50,065 epoch 34 - iter 60/202 - loss 0.67632993\n","2019-06-19 07:31:09,307 epoch 34 - iter 80/202 - loss 0.67262482\n","2019-06-19 07:31:29,272 epoch 34 - iter 100/202 - loss 0.67342396\n","2019-06-19 07:31:48,884 epoch 34 - iter 120/202 - loss 0.67069786\n","2019-06-19 07:32:10,917 epoch 34 - iter 140/202 - loss 0.66452232\n","2019-06-19 07:32:30,616 epoch 34 - iter 160/202 - loss 0.66533776\n","2019-06-19 07:32:51,876 epoch 34 - iter 180/202 - loss 0.67126890\n","2019-06-19 07:33:10,758 epoch 34 - iter 200/202 - loss 0.68778532\n","2019-06-19 07:33:11,960 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:33:11,965 EPOCH 34 done: loss 0.6877 - lr 0.0125 - bad epochs 0\n","2019-06-19 07:33:30,752 DEV : loss 0.600795567035675 - score 0.7126\n","2019-06-19 07:34:39,167 TEST : loss 0.7623056769371033 - score 0.7321\n","2019-06-19 07:34:39,176 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:34:41,368 epoch 35 - iter 0/202 - loss 0.41227275\n","2019-06-19 07:35:00,751 epoch 35 - iter 20/202 - loss 0.74741109\n","2019-06-19 07:35:21,273 epoch 35 - iter 40/202 - loss 0.73709392\n","2019-06-19 07:35:44,661 epoch 35 - iter 60/202 - loss 0.75162841\n","2019-06-19 07:36:06,666 epoch 35 - iter 80/202 - loss 0.73952361\n","2019-06-19 07:36:29,478 epoch 35 - iter 100/202 - loss 0.73546677\n","2019-06-19 07:36:50,521 epoch 35 - iter 120/202 - loss 0.70313778\n","2019-06-19 07:37:08,424 epoch 35 - iter 140/202 - loss 0.71655019\n","2019-06-19 07:37:28,487 epoch 35 - iter 160/202 - loss 0.70510309\n","2019-06-19 07:37:50,258 epoch 35 - iter 180/202 - loss 0.69005757\n","2019-06-19 07:38:07,982 epoch 35 - iter 200/202 - loss 0.69487940\n","2019-06-19 07:38:09,274 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:38:09,275 EPOCH 35 done: loss 0.7059 - lr 0.0125 - bad epochs 1\n","2019-06-19 07:38:29,966 DEV : loss 0.59144127368927 - score 0.7203\n","2019-06-19 07:39:36,928 TEST : loss 0.7502416372299194 - score 0.7435\n","2019-06-19 07:39:46,930 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:39:48,715 epoch 36 - iter 0/202 - loss 0.33282515\n","2019-06-19 07:40:08,371 epoch 36 - iter 20/202 - loss 0.69564883\n","2019-06-19 07:40:26,334 epoch 36 - iter 40/202 - loss 0.66372198\n","2019-06-19 07:40:49,854 epoch 36 - iter 60/202 - loss 0.65534782\n","2019-06-19 07:41:14,220 epoch 36 - iter 80/202 - loss 0.66103309\n","2019-06-19 07:41:38,132 epoch 36 - iter 100/202 - loss 0.66872741\n","2019-06-19 07:42:00,440 epoch 36 - iter 120/202 - loss 0.70255944\n","2019-06-19 07:42:18,652 epoch 36 - iter 140/202 - loss 0.68733287\n","2019-06-19 07:42:35,329 epoch 36 - iter 160/202 - loss 0.69172546\n","2019-06-19 07:42:56,907 epoch 36 - iter 180/202 - loss 0.70786986\n","2019-06-19 07:43:13,742 epoch 36 - iter 200/202 - loss 0.69490726\n","2019-06-19 07:43:14,945 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:43:14,947 EPOCH 36 done: loss 0.6917 - lr 0.0125 - bad epochs 0\n","2019-06-19 07:43:33,571 DEV : loss 0.5958324670791626 - score 0.7062\n","2019-06-19 07:44:41,505 TEST : loss 0.7497636675834656 - score 0.7344\n","2019-06-19 07:44:41,515 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:44:43,326 epoch 37 - iter 0/202 - loss 0.45576036\n","2019-06-19 07:45:06,836 epoch 37 - iter 20/202 - loss 0.78156481\n","2019-06-19 07:45:26,927 epoch 37 - iter 40/202 - loss 0.74632765\n","2019-06-19 07:45:46,059 epoch 37 - iter 60/202 - loss 0.70359094\n","2019-06-19 07:46:03,225 epoch 37 - iter 80/202 - loss 0.65410306\n","2019-06-19 07:46:22,358 epoch 37 - iter 100/202 - loss 0.66954696\n","2019-06-19 07:46:43,420 epoch 37 - iter 120/202 - loss 0.68018500\n","2019-06-19 07:47:07,448 epoch 37 - iter 140/202 - loss 0.68286428\n","2019-06-19 07:47:28,526 epoch 37 - iter 160/202 - loss 0.66132283\n","2019-06-19 07:47:47,535 epoch 37 - iter 180/202 - loss 0.67352347\n","2019-06-19 07:48:05,507 epoch 37 - iter 200/202 - loss 0.68286895\n","2019-06-19 07:48:06,623 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:48:06,627 EPOCH 37 done: loss 0.6803 - lr 0.0125 - bad epochs 1\n","2019-06-19 07:48:27,151 DEV : loss 0.6001402735710144 - score 0.713\n","2019-06-19 07:49:33,495 TEST : loss 0.7516741156578064 - score 0.7453\n","2019-06-19 07:49:33,504 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:49:35,471 epoch 38 - iter 0/202 - loss 0.33339047\n","2019-06-19 07:49:56,522 epoch 38 - iter 20/202 - loss 0.64295350\n","2019-06-19 07:50:15,106 epoch 38 - iter 40/202 - loss 0.72547661\n","2019-06-19 07:50:31,722 epoch 38 - iter 60/202 - loss 0.70070168\n","2019-06-19 07:50:57,356 epoch 38 - iter 80/202 - loss 0.70324668\n","2019-06-19 07:51:16,291 epoch 38 - iter 100/202 - loss 0.68522712\n","2019-06-19 07:51:35,297 epoch 38 - iter 120/202 - loss 0.68335515\n","2019-06-19 07:51:56,052 epoch 38 - iter 140/202 - loss 0.69161283\n","2019-06-19 07:52:14,174 epoch 38 - iter 160/202 - loss 0.68807224\n","2019-06-19 07:52:41,663 epoch 38 - iter 180/202 - loss 0.67440663\n","2019-06-19 07:53:00,973 epoch 38 - iter 200/202 - loss 0.67329978\n","2019-06-19 07:53:02,391 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:53:02,392 EPOCH 38 done: loss 0.6781 - lr 0.0125 - bad epochs 2\n","2019-06-19 07:53:20,882 DEV : loss 0.5985602736473083 - score 0.7141\n","2019-06-19 07:54:28,978 TEST : loss 0.7568057775497437 - score 0.7436\n","2019-06-19 07:54:28,988 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:54:30,598 epoch 39 - iter 0/202 - loss 0.49037701\n","2019-06-19 07:54:48,120 epoch 39 - iter 20/202 - loss 0.58826437\n","2019-06-19 07:55:08,240 epoch 39 - iter 40/202 - loss 0.63516258\n","2019-06-19 07:55:25,523 epoch 39 - iter 60/202 - loss 0.63104419\n","2019-06-19 07:55:47,178 epoch 39 - iter 80/202 - loss 0.65970701\n","2019-06-19 07:56:05,718 epoch 39 - iter 100/202 - loss 0.66006251\n","2019-06-19 07:56:32,417 epoch 39 - iter 120/202 - loss 0.67190593\n","2019-06-19 07:56:49,683 epoch 39 - iter 140/202 - loss 0.66679002\n","2019-06-19 07:57:10,687 epoch 39 - iter 160/202 - loss 0.65817447\n","2019-06-19 07:57:29,042 epoch 39 - iter 180/202 - loss 0.65897255\n","2019-06-19 07:57:50,331 epoch 39 - iter 200/202 - loss 0.66411203\n","2019-06-19 07:57:52,147 ----------------------------------------------------------------------------------------------------\n","2019-06-19 07:57:52,149 EPOCH 39 done: loss 0.6672 - lr 0.0125 - bad epochs 3\n","2019-06-19 07:58:12,856 DEV : loss 0.5930581092834473 - score 0.7152\n","2019-06-19 07:59:19,340 TEST : loss 0.7533398270606995 - score 0.7433\n","Epoch    38: reducing learning rate of group 0 to 6.2500e-03.\n","2019-06-19 07:59:19,349 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 07:59:21,193 epoch 40 - iter 0/202 - loss 1.11119723\n","2019-06-19 07:59:47,859 epoch 40 - iter 20/202 - loss 0.73942001\n","2019-06-19 08:00:06,882 epoch 40 - iter 40/202 - loss 0.67135401\n","2019-06-19 08:00:26,243 epoch 40 - iter 60/202 - loss 0.67704223\n","2019-06-19 08:00:48,895 epoch 40 - iter 80/202 - loss 0.66800668\n","2019-06-19 08:01:06,357 epoch 40 - iter 100/202 - loss 0.65733329\n","2019-06-19 08:01:29,676 epoch 40 - iter 120/202 - loss 0.64492116\n","2019-06-19 08:01:48,519 epoch 40 - iter 140/202 - loss 0.64228900\n","2019-06-19 08:02:03,582 epoch 40 - iter 160/202 - loss 0.65351825\n","2019-06-19 08:02:22,296 epoch 40 - iter 180/202 - loss 0.64600708\n","2019-06-19 08:02:41,617 epoch 40 - iter 200/202 - loss 0.64866456\n","2019-06-19 08:02:43,020 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:02:43,021 EPOCH 40 done: loss 0.6461 - lr 0.0063 - bad epochs 0\n","2019-06-19 08:03:01,609 DEV : loss 0.5884549021720886 - score 0.727\n","2019-06-19 08:04:09,197 TEST : loss 0.7531188130378723 - score 0.7479\n","2019-06-19 08:04:19,050 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:04:21,084 epoch 41 - iter 0/202 - loss 0.57532060\n","2019-06-19 08:04:42,460 epoch 41 - iter 20/202 - loss 0.63851432\n","2019-06-19 08:05:03,654 epoch 41 - iter 40/202 - loss 0.62769813\n","2019-06-19 08:05:26,687 epoch 41 - iter 60/202 - loss 0.59675450\n","2019-06-19 08:05:46,322 epoch 41 - iter 80/202 - loss 0.61322571\n","2019-06-19 08:06:03,625 epoch 41 - iter 100/202 - loss 0.62508135\n","2019-06-19 08:06:21,150 epoch 41 - iter 120/202 - loss 0.61467967\n","2019-06-19 08:06:41,322 epoch 41 - iter 140/202 - loss 0.62619939\n","2019-06-19 08:07:01,592 epoch 41 - iter 160/202 - loss 0.63674240\n","2019-06-19 08:07:19,143 epoch 41 - iter 180/202 - loss 0.63753401\n","2019-06-19 08:07:45,035 epoch 41 - iter 200/202 - loss 0.64071046\n","2019-06-19 08:07:46,145 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:07:46,147 EPOCH 41 done: loss 0.6396 - lr 0.0063 - bad epochs 0\n","2019-06-19 08:08:04,683 DEV : loss 0.5988706350326538 - score 0.7141\n","2019-06-19 08:09:11,102 TEST : loss 0.7587228417396545 - score 0.736\n","2019-06-19 08:09:11,109 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:09:12,684 epoch 42 - iter 0/202 - loss 1.33481479\n","2019-06-19 08:09:35,409 epoch 42 - iter 20/202 - loss 0.66315463\n","2019-06-19 08:09:56,277 epoch 42 - iter 40/202 - loss 0.66637588\n","2019-06-19 08:10:19,290 epoch 42 - iter 60/202 - loss 0.66752153\n","2019-06-19 08:10:38,598 epoch 42 - iter 80/202 - loss 0.67959249\n","2019-06-19 08:10:58,282 epoch 42 - iter 100/202 - loss 0.67167818\n","2019-06-19 08:11:15,729 epoch 42 - iter 120/202 - loss 0.65922227\n","2019-06-19 08:11:33,933 epoch 42 - iter 140/202 - loss 0.66884929\n","2019-06-19 08:11:54,551 epoch 42 - iter 160/202 - loss 0.66890913\n","2019-06-19 08:12:14,817 epoch 42 - iter 180/202 - loss 0.66218743\n","2019-06-19 08:12:34,746 epoch 42 - iter 200/202 - loss 0.65246964\n","2019-06-19 08:12:35,897 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:12:35,901 EPOCH 42 done: loss 0.6495 - lr 0.0063 - bad epochs 1\n","2019-06-19 08:12:56,524 DEV : loss 0.5895897746086121 - score 0.7172\n","2019-06-19 08:14:02,992 TEST : loss 0.7531148195266724 - score 0.7392\n","2019-06-19 08:14:03,000 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:14:04,651 epoch 43 - iter 0/202 - loss 1.16544151\n","2019-06-19 08:14:25,968 epoch 43 - iter 20/202 - loss 0.65127821\n","2019-06-19 08:14:46,565 epoch 43 - iter 40/202 - loss 0.72054709\n","2019-06-19 08:15:05,223 epoch 43 - iter 60/202 - loss 0.70496346\n","2019-06-19 08:15:26,750 epoch 43 - iter 80/202 - loss 0.68871775\n","2019-06-19 08:15:45,897 epoch 43 - iter 100/202 - loss 0.66784298\n","2019-06-19 08:16:06,300 epoch 43 - iter 120/202 - loss 0.67600177\n","2019-06-19 08:16:23,194 epoch 43 - iter 140/202 - loss 0.67407295\n","2019-06-19 08:16:41,139 epoch 43 - iter 160/202 - loss 0.66378282\n","2019-06-19 08:17:02,539 epoch 43 - iter 180/202 - loss 0.65742017\n","2019-06-19 08:17:26,017 epoch 43 - iter 200/202 - loss 0.64878824\n","2019-06-19 08:17:27,244 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:17:27,246 EPOCH 43 done: loss 0.6499 - lr 0.0063 - bad epochs 2\n","2019-06-19 08:17:45,808 DEV : loss 0.5879268050193787 - score 0.7191\n","2019-06-19 08:18:53,965 TEST : loss 0.7473369240760803 - score 0.7461\n","2019-06-19 08:18:53,972 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:18:55,748 epoch 44 - iter 0/202 - loss 0.56697047\n","2019-06-19 08:19:15,646 epoch 44 - iter 20/202 - loss 0.66263444\n","2019-06-19 08:19:33,437 epoch 44 - iter 40/202 - loss 0.69835861\n","2019-06-19 08:20:00,982 epoch 44 - iter 60/202 - loss 0.67203331\n","2019-06-19 08:20:18,300 epoch 44 - iter 80/202 - loss 0.66729973\n","2019-06-19 08:20:34,094 epoch 44 - iter 100/202 - loss 0.63853252\n","2019-06-19 08:20:53,649 epoch 44 - iter 120/202 - loss 0.65208292\n","2019-06-19 08:21:12,611 epoch 44 - iter 140/202 - loss 0.64663704\n","2019-06-19 08:21:33,950 epoch 44 - iter 160/202 - loss 0.64888176\n","2019-06-19 08:21:57,778 epoch 44 - iter 180/202 - loss 0.65288451\n","2019-06-19 08:22:15,855 epoch 44 - iter 200/202 - loss 0.65025325\n","2019-06-19 08:22:17,200 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:22:17,201 EPOCH 44 done: loss 0.6473 - lr 0.0063 - bad epochs 3\n","2019-06-19 08:22:37,788 DEV : loss 0.5902396440505981 - score 0.7133\n","2019-06-19 08:23:44,172 TEST : loss 0.7452377676963806 - score 0.7388\n","Epoch    43: reducing learning rate of group 0 to 3.1250e-03.\n","2019-06-19 08:23:44,182 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:23:46,123 epoch 45 - iter 0/202 - loss 0.88800699\n","2019-06-19 08:24:07,173 epoch 45 - iter 20/202 - loss 0.62823405\n","2019-06-19 08:24:28,090 epoch 45 - iter 40/202 - loss 0.62851617\n","2019-06-19 08:24:49,956 epoch 45 - iter 60/202 - loss 0.62094182\n","2019-06-19 08:25:07,137 epoch 45 - iter 80/202 - loss 0.62856982\n","2019-06-19 08:25:28,823 epoch 45 - iter 100/202 - loss 0.63089995\n","2019-06-19 08:25:49,150 epoch 45 - iter 120/202 - loss 0.64798371\n","2019-06-19 08:26:07,661 epoch 45 - iter 140/202 - loss 0.64868244\n","2019-06-19 08:26:28,568 epoch 45 - iter 160/202 - loss 0.64349840\n","2019-06-19 08:26:47,066 epoch 45 - iter 180/202 - loss 0.64387434\n","2019-06-19 08:27:09,961 epoch 45 - iter 200/202 - loss 0.63906043\n","2019-06-19 08:27:11,130 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:27:11,132 EPOCH 45 done: loss 0.6401 - lr 0.0031 - bad epochs 0\n","2019-06-19 08:27:29,701 DEV : loss 0.5851803421974182 - score 0.7265\n","2019-06-19 08:28:35,948 TEST : loss 0.7409335374832153 - score 0.7401\n","2019-06-19 08:28:35,956 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:28:38,200 epoch 46 - iter 0/202 - loss 0.16071957\n","2019-06-19 08:28:57,848 epoch 46 - iter 20/202 - loss 0.64519801\n","2019-06-19 08:29:18,496 epoch 46 - iter 40/202 - loss 0.62662178\n","2019-06-19 08:29:43,175 epoch 46 - iter 60/202 - loss 0.64054690\n","2019-06-19 08:30:05,495 epoch 46 - iter 80/202 - loss 0.63230420\n","2019-06-19 08:30:24,178 epoch 46 - iter 100/202 - loss 0.62421886\n","2019-06-19 08:30:43,705 epoch 46 - iter 120/202 - loss 0.62127268\n","2019-06-19 08:31:02,283 epoch 46 - iter 140/202 - loss 0.61662968\n","2019-06-19 08:31:22,662 epoch 46 - iter 160/202 - loss 0.61619214\n","2019-06-19 08:31:42,779 epoch 46 - iter 180/202 - loss 0.62498532\n","2019-06-19 08:32:02,009 epoch 46 - iter 200/202 - loss 0.62664781\n","2019-06-19 08:32:03,110 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:32:03,112 EPOCH 46 done: loss 0.6237 - lr 0.0031 - bad epochs 1\n","2019-06-19 08:32:21,581 DEV : loss 0.5796281695365906 - score 0.7213\n","2019-06-19 08:33:29,215 TEST : loss 0.734861433506012 - score 0.7499\n","2019-06-19 08:33:29,223 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:33:30,743 epoch 47 - iter 0/202 - loss 0.48001915\n","2019-06-19 08:33:51,353 epoch 47 - iter 20/202 - loss 0.62606771\n","2019-06-19 08:34:10,662 epoch 47 - iter 40/202 - loss 0.70781910\n","2019-06-19 08:34:34,085 epoch 47 - iter 60/202 - loss 0.65882861\n","2019-06-19 08:34:55,996 epoch 47 - iter 80/202 - loss 0.66047295\n","2019-06-19 08:35:15,341 epoch 47 - iter 100/202 - loss 0.64801976\n","2019-06-19 08:35:35,145 epoch 47 - iter 120/202 - loss 0.63845566\n","2019-06-19 08:35:51,459 epoch 47 - iter 140/202 - loss 0.62917494\n","2019-06-19 08:36:11,091 epoch 47 - iter 160/202 - loss 0.62521745\n","2019-06-19 08:36:29,983 epoch 47 - iter 180/202 - loss 0.63938633\n","2019-06-19 08:36:53,639 epoch 47 - iter 200/202 - loss 0.63745360\n","2019-06-19 08:36:54,801 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:36:54,803 EPOCH 47 done: loss 0.6352 - lr 0.0031 - bad epochs 2\n","2019-06-19 08:37:13,414 DEV : loss 0.5858591794967651 - score 0.7198\n","2019-06-19 08:38:19,457 TEST : loss 0.7401309013366699 - score 0.7469\n","2019-06-19 08:38:19,465 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:38:21,213 epoch 48 - iter 0/202 - loss 0.59012336\n","2019-06-19 08:38:46,482 epoch 48 - iter 20/202 - loss 0.74487748\n","2019-06-19 08:39:06,190 epoch 48 - iter 40/202 - loss 0.67972841\n","2019-06-19 08:39:29,376 epoch 48 - iter 60/202 - loss 0.66587459\n","2019-06-19 08:39:47,320 epoch 48 - iter 80/202 - loss 0.66465512\n","2019-06-19 08:40:04,227 epoch 48 - iter 100/202 - loss 0.65409887\n","2019-06-19 08:40:24,573 epoch 48 - iter 120/202 - loss 0.64433278\n","2019-06-19 08:40:45,948 epoch 48 - iter 140/202 - loss 0.63462944\n","2019-06-19 08:41:02,089 epoch 48 - iter 160/202 - loss 0.62485003\n","2019-06-19 08:41:22,542 epoch 48 - iter 180/202 - loss 0.63249407\n","2019-06-19 08:41:42,876 epoch 48 - iter 200/202 - loss 0.64031942\n","2019-06-19 08:41:44,327 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:41:44,330 EPOCH 48 done: loss 0.6391 - lr 0.0031 - bad epochs 3\n","2019-06-19 08:42:04,920 DEV : loss 0.5791105628013611 - score 0.7228\n","2019-06-19 08:43:11,083 TEST : loss 0.7338737845420837 - score 0.7472\n","Epoch    47: reducing learning rate of group 0 to 1.5625e-03.\n","2019-06-19 08:43:11,091 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:43:13,829 epoch 49 - iter 0/202 - loss 0.46155363\n","2019-06-19 08:43:33,944 epoch 49 - iter 20/202 - loss 0.63576560\n","2019-06-19 08:43:57,106 epoch 49 - iter 40/202 - loss 0.59370072\n","2019-06-19 08:44:12,982 epoch 49 - iter 60/202 - loss 0.58774920\n","2019-06-19 08:44:33,737 epoch 49 - iter 80/202 - loss 0.61339218\n","2019-06-19 08:44:54,601 epoch 49 - iter 100/202 - loss 0.60351284\n","2019-06-19 08:45:14,216 epoch 49 - iter 120/202 - loss 0.63244889\n","2019-06-19 08:45:35,233 epoch 49 - iter 140/202 - loss 0.63415297\n","2019-06-19 08:45:54,973 epoch 49 - iter 160/202 - loss 0.62232890\n","2019-06-19 08:46:14,070 epoch 49 - iter 180/202 - loss 0.62733339\n","2019-06-19 08:46:37,730 epoch 49 - iter 200/202 - loss 0.62914341\n","2019-06-19 08:46:39,260 ----------------------------------------------------------------------------------------------------\n","2019-06-19 08:46:39,261 EPOCH 49 done: loss 0.6307 - lr 0.0016 - bad epochs 0\n","2019-06-19 08:46:57,805 DEV : loss 0.5822362303733826 - score 0.7214\n","2019-06-19 08:48:04,094 TEST : loss 0.738160252571106 - score 0.7437\n","2019-06-19 08:48:04,105 ----------------------------------------------------------------------------------------------------\n","train mode resetting embeddings\n","train mode resetting embeddings\n","2019-06-19 08:48:06,340 epoch 50 - iter 0/202 - loss 1.57350254\n","2019-06-19 08:48:28,584 epoch 50 - iter 20/202 - loss 0.63681223\n","2019-06-19 08:48:47,696 epoch 50 - iter 40/202 - loss 0.64074348\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"df7YLR6ZBNww","colab_type":"text"},"source":["##**Plot loss and weights history:**"]},{"cell_type":"code","metadata":{"id":"fUhGu6aY_1fg","colab_type":"code","colab":{}},"source":["# 8. plot training curves (optional)\n","from flair.visual.training_curves import Plotter\n","plotter = Plotter()\n","plotter.plot_training_curves('./resources_best_config/taggers/resume-ner/loss.tsv')\n","plotter.plot_weights('./resources_best_config/taggers/resume-ner/weights.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y26FnQCeB4fq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}